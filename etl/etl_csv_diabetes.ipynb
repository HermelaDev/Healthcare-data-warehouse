{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10ecbfb2-71fe-47cf-8838-d88cbd1d1836",
   "metadata": {},
   "source": [
    "## ETL for Diabetes Encounter Data (CSV file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613b5bd6-920b-4504-96f8-901447b7cc5a",
   "metadata": {},
   "source": [
    "#### 1. Import Libraries & Load Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c619d8ce-105d-479d-8d5e-c0b39de142ab",
   "metadata": {},
   "source": [
    "This block loads the required libraries and database engine from the config file, ensuring connection parameters are centralized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d40e97f1-5503-48b5-96e0-5dec6b9197ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from config import pg_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714fc74b-8913-47a2-8220-383888b1cd90",
   "metadata": {},
   "source": [
    "#### 2. Extract: Read the Diabetes CSV File"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709e850d-e359-40e0-af37-0d713070bff6",
   "metadata": {},
   "source": [
    "The raw clinical dataset is imported into a DataFrame. This acts as the core source for patient encounters, diagnoses, and hospital events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2bcc2751-e0d9-47b4-a266-8fda9dd6fb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\Admin\\Documents\\GitHub\\Healthcare-data-warehouse\\source_data\\diabetic_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316f45a1-a424-41da-a2b6-72108d3b2d7b",
   "metadata": {},
   "source": [
    "#### 3. Clean & Preprocess Raw Data\n",
    "\n",
    "This step standardizes missing values, removes unusable rows, enforces data consistency, and recasts numeric fields.\n",
    "It ensures the dataset is analysis-ready before dimension construction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c63a60e1-f44b-4b9b-ab48-b0ede0eb72b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace(\"?\", None, inplace=True)\n",
    "df = df.dropna(subset=[\"encounter_id\", \"patient_nbr\"])\n",
    "df = df.drop_duplicates(subset=[\"encounter_id\"])\n",
    "\n",
    "numeric_cols =     [\"time_in_hospital\",\n",
    "    \"num_lab_procedures\",\n",
    "    \"num_procedures\",\n",
    "    \"num_medications\",\n",
    "    \"number_outpatient\",\n",
    "    \"number_emergency\",\n",
    "    \"number_inpatient\",\n",
    "    \"number_diagnoses\",]\n",
    "for col in numeric_cols:\n",
    "    df[col] = pd.to_numeric(df[col], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e29bd10-468f-4d43-8110-b15c30cf7960",
   "metadata": {},
   "source": [
    "#### 4. Derive Additional Features\n",
    "\n",
    "Feature engineering adds business-useful fields such as readmission flags and age groups.\n",
    "It also aligns column names to match PostgreSQL schemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8647b107-3fc9-4a9a-9679-95f926fc0551",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"readmitted_raw\"] = df[\"readmitted\"]\n",
    "df[\"readmitted_30d_flag\"] = df[\"readmitted\"].apply(lambda x: x == \"<30\")\n",
    "df[\"age_group\"] = df[\"age\"]\n",
    "df[\"diabetesmed\"] = df[\"diabetesMed\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c6988a-aa84-4b28-89db-5c9e66e00803",
   "metadata": {},
   "source": [
    "Standardizing admission ID datatypes avoids join mismatches later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "96eaec99-7f02-4fb3-bb7f-2f1834fdf330",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\"admission_type_id\", \"discharge_disposition_id\", \"admission_source_id\"]:\n",
    "    df[col] = df[col].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445337ea-17a5-49b2-a2bb-7ed468ff8633",
   "metadata": {},
   "source": [
    "#### 5. Transform: Build Patient Dimension (dim_patient)\n",
    "\n",
    "This extracts patient-level attributes and ensures one record per patient.\n",
    "It forms the foundation for all patient-based analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0666bf60-1e13-4bf5-8c80-093ac33a967e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_patient = (\n",
    "    df[[\"patient_nbr\", \"race\", \"gender\", \"age_group\", \"payer_code\"]]\n",
    "    .drop_duplicates(subset=[\"patient_nbr\"])\n",
    ")\n",
    "dim_patient[\"source_system\"] = \"CSV_diabetes\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d400f11e-733d-4eb9-bb12-487203172410",
   "metadata": {},
   "source": [
    "#### 6. Transform: Build Admission Dimension (dim_admission)\n",
    "\n",
    "Admission-related metadata is normalized into a clean lookup table.\n",
    "This supports analysis of hospital intake patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ae043cbd-460c-4cfb-a386-a6fde0ed4bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_admission = (\n",
    "    df[[\"admission_type_id\", \"discharge_disposition_id\", \"admission_source_id\"]]\n",
    "    .drop_duplicates()\n",
    ")\n",
    "dim_admission.rename(\n",
    "    columns={\n",
    "        \"admission_type_id\": \"admission_type\",\n",
    "        \"discharge_disposition_id\": \"discharge_disposition\",\n",
    "        \"admission_source_id\": \"admission_source\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "dim_admission[\"source_system\"] = \"CSV_diabetes\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338d18ce-1162-4269-944a-85d3ded8f137",
   "metadata": {},
   "source": [
    "#### 7. Transform: Build Diagnosis Dimension (dim_diagnosis)\n",
    "\n",
    "Diagnosis codes from three columns are unpivoted, deduplicated, and categorized by ICD prefix.\n",
    "This aligns clinical coding into an analytic dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f9d27d36-80b7-4423-a963-18c9633a8404",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_long = (\n",
    "    pd.melt(\n",
    "        df[[\"encounter_id\", \"diag_1\", \"diag_2\", \"diag_3\"]],\n",
    "        id_vars=[\"encounter_id\"],\n",
    "        value_vars=[\"diag_1\", \"diag_2\", \"diag_3\"],\n",
    "        var_name=\"diag_position\",\n",
    "        value_name=\"diagnosis_code\",\n",
    "    )\n",
    "    .dropna(subset=[\"diagnosis_code\"])\n",
    "    .drop_duplicates(subset=[\"diagnosis_code\"])\n",
    ")\n",
    "diag_long[\"icd_category\"] = diag_long[\"diagnosis_code\"].str.slice(0, 3)\n",
    "dim_diagnosis = diag_long[[\"diagnosis_code\", \"icd_category\"]].drop_duplicates()\n",
    "dim_diagnosis[\"source_system\"] = \"CSV_diabetes\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7d9b1f-4682-45f9-94f0-e7bd813a7096",
   "metadata": {},
   "source": [
    "#### 8. Load Dimensions into PostgreSQL\n",
    "\n",
    "To maintain repeatable ETL runs, dimension tables are truncated and reloaded.\n",
    "This ensures consistency and avoids leftover data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d3180b2d-3cd3-439d-968a-7d7da1ae3cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pg_engine.begin() as conn:\n",
    "    # Make the load repeatable: clear dims first\n",
    "    conn.exec_driver_sql(\"TRUNCATE TABLE dim_diagnosis RESTART IDENTITY CASCADE;\")\n",
    "    conn.exec_driver_sql(\"TRUNCATE TABLE dim_admission RESTART IDENTITY CASCADE;\")\n",
    "    conn.exec_driver_sql(\"TRUNCATE TABLE dim_patient RESTART IDENTITY CASCADE;\")\n",
    "\n",
    "    dim_patient.to_sql(\"dim_patient\", con=conn, if_exists=\"append\", index=False)\n",
    "    dim_admission.to_sql(\"dim_admission\", con=conn, if_exists=\"append\", index=False)\n",
    "    dim_diagnosis.to_sql(\"dim_diagnosis\", con=conn, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a298be12-ecf6-47e9-93d4-840c8cdb575b",
   "metadata": {},
   "source": [
    "#### 9. Extract Dimension Keys for Fact Table Construction\n",
    "\n",
    "The ETL retrieves dimension tables to build mapping dictionaries.\n",
    "These allow efficient FK assignment in the fact table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "975e1bd6-bbf6-4cec-b7f4-52f74d4e52f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-read dimensions with keys to build fact\n",
    "with pg_engine.connect() as conn:\n",
    "    dim_patient_db = pd.read_sql(\"SELECT * FROM dim_patient\", conn)\n",
    "    dim_admission_db = pd.read_sql(\"SELECT * FROM dim_admission\", conn)\n",
    "    dim_diag_db = pd.read_sql(\"SELECT * FROM dim_diagnosis\", conn)\n",
    "\n",
    "patient_key_map = dim_patient_db.set_index(\"patient_nbr\")[\"patient_key\"].to_dict()\n",
    "admission_key_map = (\n",
    "    dim_admission_db\n",
    "    .set_index([\"admission_type\", \"discharge_disposition\", \"admission_source\"])[\"admission_dim_key\"]\n",
    "    .to_dict()\n",
    ")\n",
    "diag_key_map = dim_diag_db.set_index(\"diagnosis_code\")[\"diagnosis_key\"].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebfb2ef-6e12-483d-9397-3ac65968cfe2",
   "metadata": {},
   "source": [
    "#### 10. Assign Foreign Keys to the Fact Data\n",
    "\n",
    "Keys from the dimension tables are mapped into the main encounter dataset.\n",
    "This links clinical events to the dimensional model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0183789a-1356-487d-8796-d68a9c961c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"patient_key\"] = df[\"patient_nbr\"].map(patient_key_map)\n",
    "df[\"admission_dim_key\"] = df.apply(\n",
    "    lambda row: admission_key_map.get(\n",
    "        (row[\"admission_type_id\"],\n",
    "         row[\"discharge_disposition_id\"],\n",
    "         row[\"admission_source_id\"])\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "df[\"primary_diagnosis_key\"] = df[\"diag_1\"].map(diag_key_map)\n",
    "df[\"secondary_diagnosis_key\"] = df[\"diag_2\"].map(diag_key_map)\n",
    "df[\"tertiary_diagnosis_key\"] = df[\"diag_3\"].map(diag_key_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb501509-5e88-4af8-bda6-0ddf1e656199",
   "metadata": {},
   "source": [
    "#### 11. Select Required Fact Table Columns\n",
    "\n",
    "A clean fact record is created containing keys, clinical measures, and outcome indicators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fdd8b654-99b4-4928-8081-561bca4cb2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_cols = [\n",
    "    \"encounter_id\",\n",
    "    \"patient_key\",\n",
    "    \"admission_dim_key\",\n",
    "    \"primary_diagnosis_key\",\n",
    "    \"secondary_diagnosis_key\",\n",
    "    \"tertiary_diagnosis_key\",\n",
    "    \"time_in_hospital\",\n",
    "    \"num_lab_procedures\",\n",
    "    \"num_procedures\",\n",
    "    \"num_medications\",\n",
    "    \"number_outpatient\",\n",
    "    \"number_emergency\",\n",
    "    \"number_inpatient\",\n",
    "    \"number_diagnoses\",\n",
    "    \"readmitted_raw\",\n",
    "    \"readmitted_30d_flag\",\n",
    "    \"change\",\n",
    "    \"diabetesmed\",\n",
    "]\n",
    "\n",
    "fact_df = df[fact_cols].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fca4276-23d3-4ffd-bc5e-b5bbcee16dcc",
   "metadata": {},
   "source": [
    "#### 12. Filter Invalid Records\n",
    "\n",
    "Encounter rows missing patient foreign keys are removed to enforce relational integrity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0827d4ad-a5cf-4148-b7d9-cad98c82681f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only rows with a valid patient_key\n",
    "fact_df = fact_df.dropna(subset=[\"patient_key\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4f9913-6b9f-442b-8fde-018a7e18a046",
   "metadata": {},
   "source": [
    "#### 13. Load Fact Table into PostgreSQL\n",
    "\n",
    "The fact table is truncated for clean reloading and populated with the transformed records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1ad25661-9dcb-4225-a31f-084553aa4200",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_df[\"source_system\"] = \"CSV_diabetes\"\n",
    "\n",
    "with pg_engine.begin() as conn:\n",
    "    conn.exec_driver_sql(\"TRUNCATE TABLE fact_hospital_admission_parted RESTART IDENTITY;\")\n",
    "\n",
    "    fact_df.to_sql(\n",
    "        \"fact_hospital_admission_parted\",\n",
    "        con=conn,\n",
    "        if_exists=\"append\",\n",
    "        index=False,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
